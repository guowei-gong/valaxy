---
title: 从CPU的角度考虑性能优化
date: 2022-08-25 10:01:44
categories: 关于计算机科学
---

我们学习和研究计算机体系结构，就是为了理解计算机是如何运作的，以及......为！什！么！要！这！么！运！作！。为什么这么运作的目的，就是为了提升"性能"。

计算机的性能，主要由如下两个指标衡量。

- 吞吐率。在一定时间内，能处理多少数据或者指令。服务器使用的网络带宽，通常就是一个吞吐率的性能指标。
- 响应时间。即执行时间。执行一个程序，需要花费的时间。

因此，提升性能，我们可以缩短响应时间，提高吞吐率。

那什么是性能？性能一般看做响应时间的倒数，即：

<div class="success">

> 性能 = 1 / 响应时间

</div>

响应时间越短，性能的数值也就越高。例如执行一个程序，现在的 `CPU` 芯片只需要 30 S 就能运行完成，而在以前的 `CPU` 需要 1 min 才能完成，那以前的 `CPU` 性能是 1/60，现在的 `CPU` 是 1/30，两个**性能比**为 2。于是我们可以说，现在的 `CPU` 是以前 `CPU` 性能的 2 倍。

用时间来衡量性能，存在两个问题。首先就是时间不"准"。例如我们随便写一个程序，每次运行的时间可能都不一样。原因是响应时间由三部分组成，分别是：

- real time。运行程序整个过程使用的时间。
- user time。`CPU` 用户态运行指令使用的时间。
- sys time。`CPU` 内核里运行指令的时间。

影响这三部分的因素有`CPU`、主板、网络、硬盘、内存等硬件。real time 包含了这些影响因素所占用的时间。

<div class="success">

> 程序在 CPU 中实际运行的时间 = user time + sys time
> 非程序实际运行时间（由硬件因素引起的耗时）= real time - (user time + sys time)

</div>

>real time 有些时候可能会小于 user time + sys time，原因是在多 `CPU` 的机器上，指令可能被分配到不同的 `CPU` 上，我们拿到的 user time 和 sys time 是两个 `CPU` 上花费的时间之和。

我们拿到程序在 `CPU` 的中实际运行时间，也不一定能够比较两个程序的性能，因为 `CPU` 可能满载运行也可能降频运行，降频运行的时候，花的时间自然更多。为了不受降频的影响，需要把程序在 `CPU` 的中实际运行时间拆分，去除降频影响的部分，拆分如下。

<div class="success">

> 程序的 CPU 执行时间 = CPU 时钟 x (周期数 + 周期时间)

</div>

周期时间可以理解成购买 `CPU` 时，我们往往能够看到 2.8GHz 主频，这就可以看做周期时间，可以粗略理解为 `CPU` 在 1 秒内，可以执行的简单指令数量是 2.8G 条。如果准确一点的描述，2.8GHZ 代表 `CPU` 一个"钟表"能够识别出来的**最小时间间隔**。

钟表指的是 `CPU` 内部的晶体振荡器。晶振每"滴答"一次，就是周期时间。周期时间越大，`CPU` 也就执行指令越快。

影响程序的 `CPU` 执行时间的另一个因子，`CPU` 时钟周期数，它同样可以分解，如下。

<div class="success">

> CPU 时钟周期数 = 指令数 × 每条指令的平均时钟周期数

</div>

每条指令需要的周期数是不同的，例如加法和乘法都对应一条 `CPU` 指令，但是乘法需要的周期比加法多，自然也就更慢。

<div class="success">

> 程序的 CPU 执行时间 = 指令数 × 每条指令的平均时钟周期数 x CPU 时钟周期时间

</div>

因此，我们想要提升性能，其实就是需要优化这三者。
- 指令数。代表执行我们的程序到底需要多少条指令、用哪些指令。这个挑战交给了编译器。
- `CPU` 时钟周期时间。也就是 `CPU` 主频。
- 每条指令的平均时钟周期数。一条指令需要多少周期。

> 参考资料 - 徐文浩-深入浅出计算机组成原理